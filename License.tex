\documentclass[12 pct]{report}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[english]{babel}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}
\usepackage{wrapfig}
\usepackage[english]{isodate}
\usepackage{titling}
\usepackage[left=1.5in, right=1.5in, top=1in, bottom=1in]{geometry}
\usepackage{setspace}
\graphicspath{ {/Users/so/Desktop/Projects/ArRobotLearnToCodePRoject/} }
\setcounter{section}{-1}

\setstretch{1.5}
\begin{document}
\begin{titlepage}
\title{\vspace{-3.5cm}
  { \huge BabeÈ™-Bolyai University\\
  Faculty of Mathematics and Computer\\
  Science\\
  Computer Science English Specialisation \\
  }
  \ \\
  \ \\
  {\huge \textbf{Diploma Thesis}}
  \ \\
  \ \\
  \textbf{Alternative methods of learning using Augmented Reality\\
  Practical application \\
    and comparisons with other techniques
  }
  \ \\
  \ \\
  {%
    \setstretch{0}
    \begin{flushleft}%
  	 Scientific supervisor
  	\end{flushleft}
  	\begin{flushleft}%
  	 Dr. Lector Cojocar Dan
  	\end{flushleft}}
  {%
  \setstretch{0}
  \begin{flushright}
  	Author
  \end{flushright}
  \begin{flushright}
  	Mircea Sorin-Sebastian
  \end{flushright} }
}%
\date{2019\\}
\maketitle
\end{titlepage}

\begin{titlepage}
\title{\vspace{-3.5cm}
  { \huge Universitatea BabeÈ™-Bolyai\\
  Facultatea de MatematicÄƒ È™i InformaticÄƒ\\
  Specializarea InformaticÄƒ Ã®n limba EnglezÄƒ \\
  }
  \ \\
  \ \\
  {\huge \textbf{Lucrare de licenÈ›Äƒ}}
  \ \\
  \ \\
  \textbf{
  Metode alternative de Ã®nvÄƒÈ›are folosind Realitatea AugmentatÄƒ\\
  AplicaÈ›ii practice È™i comparaÈ›ii cu alte tehnici
  }
  \ \\
  \ \\
   {%
    \setstretch{0}
    \begin{flushleft}%
  	 Conduc›Äƒtor È™tiinÈ›ific
  	\end{flushleft}
  	\begin{flushleft}%
  	 Dr. Lector Cojocar Dan
  	\end{flushleft}}
  {%
  \setstretch{0}
  \begin{flushright}
  	Autor
  \end{flushright}
  \begin{flushright}
  	Mircea Sorin-Sebastian
  \end{flushright} }
}%
\maketitle
\end{titlepage}

\setstretch{1.5}
\begin{abstract}
The way that people acquire new knowledge and interact with the information has remained more or less the same over history, evolving from paper-based books to digital ebooks. 
The interaction with the information is practically non-existent, even more, the medium of showing the information is only two-dimensional, making the understanding of the real world, three-dimensional concepts more difficult. 
Augmented Reality, as a technology, has dramatically improved in the past few years and now has the power to reshape the process of learning and teaching in ways that are still not contoured. 
This paper proposes two new different educational purposed applications that rely on distinct types of Augmented Reality.
\end{abstract}

\tableofcontents

\listoffigures

\listoftables

\chapter{Introduction}

\section{Motivation}
On the grounds that in recent years, the rate of technological advancements is increasing exponentially makes it our responsibility always to keep looking towards new ways of exploiting to the maximum the power of such technologies. 
Moreover, when breakthroughs are powerful enough to enter into the public's attention, it triggers and stimulates the desire to increase the research activity in that field, thus forming a circle that is in our interests to not break it.

\begin{figure}[H]
\includegraphics[width=0.59\textwidth]{ar-chart}
\centering
\label{fig:feature-points}
\caption{Augmented reality market size \cite{consultancy.uk}}
\end{figure}

Augmented Reality (AR) \cite{azuma2001recent} is one of the most promising technologies that have risen in the past years. 
It has a real potential to provide a boost in already existing applications across a multitude of domains, and even more to redefine and explore entirely new use-cases, a path that is in active research and encouraged by this work to be explored.

As for the actual field which is the target of this study, Education, due to its major importance in forming new generations of capable people, the efforts to continuously find ways to improve are definitely worth it. 
We believe that Augmented Reality has the power to enhance the digital methods of learning by bringing the experience closer to the in-class one and in some cases even beyond \cite{wu2013current}.

\section{Objective}
The objective of this work is to find new uses of recent technological advancements in Augmented Reality for the education sector and to research the effectiveness, feasibility of deploying such approaches to the general public. Also, to provide additional directions for future developments so that they enable the forthcoming applications to have the power of redefining the already existing processes of learning.

\section{Structure}
The paper is divided into two major parts, the theoretical one that includes a description of how Augmented Reality works and the progress that has been made in this field, followed by an in-depth depiction of the advantages that can be brought to the traditional means of learning. 
In the second part, the theoretical notions presented are applied into two applications.
One being focused on the musical domain, in more detail in teaching people of all ages the basics of learning the piano.
And the other targeting young kids wishing to learn how to code. 
Both applications are making use of different types of Augmented Reality devices like smart glasses \cite{rauschnabel2016augmented} and handheld mobile devices \cite{wagner2005towards}.

\chapter{Augmented Reality}

\section{Introduction}
The meaning of the word augment is to add or enhance something. In the case of Augmented Reality \cite{milgram1995augmented} graphics, sounds, and different feedback are added to our world to create an enhanced experience.

This approach is opposite to the one that Virtual Reality \cite{burdea2003virtual}  takes, which is to completely replace the reality with a computer generated one.

\section{Categories of Augmented Reality}
\begin{figure}[h!]
  \centering
  \begin{subfigure}[b]{0.36\linewidth}
    \includegraphics[width=\linewidth]{marker-based}
     \caption{Marker based \cite{wagner2003first}}
     
  \end{subfigure}
  \begin{subfigure}[b]{0.4\linewidth}
    \includegraphics[width=\linewidth]{marker-less}
    \caption{Markerless \cite{comport2006real}}
  \end{subfigure}
  \begin{subfigure}[b]{0.4\linewidth}
    \includegraphics[width=\linewidth]{projection-based}
    \caption{Projection \cite{mine2012projection}}
  \end{subfigure}
  \begin{subfigure}[b]{0.4\linewidth}
    \includegraphics[width=\linewidth]{super-imposition}
    \caption{Superimposition \cite{milgram1995augmented}}
  \end{subfigure}
  \caption{Categories of augmented reality}
  \label{fig:coffee3}
\end{figure}
Having their own use cases, advantages, and disadvantages, several types of augmented reality approaches exist.

\subsection*{Marker based}
Uses a camera-enabled device and some type of visual markers (like QR codes or specific feature points) to recognize these zones and execute certain actions like imposing a virtual object over the marker \cite{wagner2003first}  .
 
\subsection*{Markerless}
Also known as location-based AR, it uses GPS, digital compass, velocity meter, and accelerometer to track and recognize the position of the phone, making possible the instantiation of virtual objects that appear to remain in place even if the user moves through the world.

\subsection*{Projection based}
The augmentation is realized by projecting light onto objects (the projection can also be made in mid-air with the help of laser plasma technology), though augmenting it. One use-case would be creating an interactive virtual keyboard.


\subsection*{Superimposition based}
In this approach, the original view is either fully or partially replaced with a newly generated augmented view. For this to happen, the object that needs to be replaced must first be detected, so image processing plays a vital role.


\section{Types of Devices}
\begin{figure}[h!]
  \centering
  \begin{subfigure}[b]{0.4\linewidth}
    \includegraphics[width=\linewidth]{head-up}
    \caption{Head Up Display}
    \label{fig:headupdisplay}
  \end{subfigure}
  \begin{subfigure}[b]{0.4\linewidth}
    \includegraphics[width=\linewidth]{helmet-mounted}
    \caption{Helmet Mounted Display}
    \label{fig:helmetdisplay}
  \end{subfigure}
  \begin{subfigure}[b]{0.4\linewidth}
    \includegraphics[width=\linewidth]{holographic-display}
    \caption{Holographic Display}
  \end{subfigure}
  \begin{subfigure}[b]{0.4\linewidth}
    \includegraphics[width=\linewidth]{smart-glasses}
    \caption{Smart glasses}
  \end{subfigure}
  \begin{subfigure}[b]{0.4\linewidth}
    \includegraphics[width=\linewidth]{hand-held}
    \caption{Handheld}
  \end{subfigure}
  \caption{Types of AR enabled devices}
  \label{fig:artypes}
\end{figure}

\subsection*{Head up displays}
Mainly invented for mission-critical applications \cite{livingston2011military} like flight controllers and weapon system dashboards where crucial information needs to be presented directly in the visual field of the user. In this case, the projected information is collimated (parallel light rays), focused on infinity so that the userâ€™s eyes do not need to refocus to view outside the world.
A regular HUD \cite{beckwith2015augmented} is composed out of a projector unit, a viewing glass and a computer that generates the data that needs to be shown.

\subsection*{Helmet mounted displays}
Represents the next logical step from the head up displays (See Fig. \ref{fig:headupdisplay}) moving the display from a fixed position to a mobile one, mounted directly on the helmet (See Fig. \ref{fig:helmetdisplay})

\subsection*{Holographic displays}
They use light diffraction \cite{lucente1997interactive} to generate three-dimensional forms of an object in real space

\subsection*{Smart glasses}
As the use case of Augmented Reality transitioned from critical applications (mostly used by the army) to applications available for the general mass of user, helmet mounted displays shifted toward a lighter form-factor, integrated directly in smart glasses. 

\subsection*{Handheld AR}
The majority of mobile devices enter in this category, as both major mobile software providers, iOS \cite{wilson2007iphone} and Android \cite{rogers2009android} offer augmented reality support (ARKit and ARCore). The advantage of this approach is that it makes augmented reality accessible to anyone with a decent smartphone, the drawback being the fact the user experience is not always satisfying as you always need to hold and pinpoint the device towards the zone you want to interact with

\section{ARKit}
It is a framework that does tracking, scene understanding, and rendering, thus taking the heavy lift from the developer (as you only need to anchor virtual objects to the real world, and they stay glued to the physical position they were placed).

ArKit uses a technique called visual-inertial odometry (VIO). In more detail, the position of the phone is tracked via the Visual system (camera), by matching a point in the real world (called feature point) to a pixel on the camera sensor for each frame. In parallel, the pose is also tracked by the Inertial system  (also called IMU) formed of an accelerometer and gyroscope. These two outputs are combined via a Kalman filter to determine which of the two systems provides the best estimate of the real position.

\begin{figure}[]
\includegraphics[width=1\textwidth]{feature-points}
\centering
\label{fig:feature-points}
\caption{ARKit feature points}
\end{figure}

The Visual system is refreshed every time a new frame is captured by the camera (30 times per second), while the inertial system outputs 1000 readings per second. Both the systems alone would accumulate errors in a specific condition, but the fact that there are no interdependencies between them leads to an overall much better performance. For example, the visual systems output weak results if the image is shaken, if the light is weak, or the targeted object has a smooth surface (without particularities, like glass, or an entirely white wall), during this time the Inertial part carries the load, and vice-versa in the case that the device is still (so there is no inertial data), the camera has the possibility to capture more accurate data, thus receiving priority as being closer to the truth from the Kalman filter \cite{matt2017arkit}.

\subsection*{Plane detection}
\begin{figure}[H]
\includegraphics[width=1\textwidth]{plane-detection}
\centering
\label{fig:plane-detection}
\caption{ARKit plane detection spawning blue plane}
\end{figure}

In order to create an AR experience that can blend with reality, the ability to place an object on the ground represents one of the critical requirements. 

This can be achieved using the feature points detected by the Visual system, every three points are considered to define a plane, and after doing multiple such calculations, the plane that represents the ground can be estimated.

\chapter{Improvements in Learning by Using Augmented Reality}
\section{Introduction}
According to \cite{shapley2011effects}, lessons that are supported by technology will lead to more innovative forms of teaching and learning. This is because the use of technology involves real-world problems, current informational resources, simulations of concepts, and communication with professionals in the filed. In addition, learning using technology is believed to complement the traditional forms of teaching and learning \cite{saidinar}

In recent years, as augmented reality emerged as a new technology, its potential for applications in education was discovered, and the interest grew steadily. In research conducted by Teoh and Neo (2007) \cite{teoh2007interactive}, the respondents reported that it was boring just to hear the lecturer talking in front of them. The students believed that the integration of technology would help them in their learning process.

\section{Impact of Using Augmented Reality in Learning}
One of the aspects that discourage future students in following a science path is the thought that grasping theoretical aspects it is going to impose them real problems \cite{baker2009educational}. 
The majority of difficulties that appear are related to understanding multi-dimensional data \cite{pao1998visualization}.

Augmented Reality is an excellent way of visualizing three-dimensional objects, as it replaces classical wood or cartoon physical shapes that are used by teachers with virtual, augmented objects \cite{schmalstieg2007managing}. 
Also, there are situations that not only require a three dimensional way of showing objects but to also provide a way to observe dynamical interactions with the studied item.
Like exploring the surface or planet Mars, or other planets that are not yet easily accessible to the humankind \cite{hollerer1999exploring}.

The use of AR would also increase the time that students can spend studying different objects that otherwise would only be accessible inside the school hours or only in some special laboratories, thus providing an unrestrained amount of study time \cite{yoon2014making}.

\begin{table}[H]
\centering
 \begin{tabular}{||p{20mm} p{30mm} p{40mm} p{30mm}||} 
 \hline
 Author/s & Field & Purpose of AR Use & AR Features Used \\ [0.5ex] 
 \hline\hline
 Chang et al. 2011) & Medical education (surgical training) & To provide training and to plan and guide surgical procedures & AR image-guided therapy \\ 
 Yeom (2011) & Medical education (anatomy) & To teach and test anatomy knowledge (of the abdomen in particular)  & interactive 3D anatomy pictures and haptic feedback \\
 Hedegaard et al.(2007) & Medical education using the electrocardiogram (ECG/EKG) AR system (called the EKGAR system) & To extend medical studentsâ€™ spatial awareness in relation to specific myocardial diseases by enabling users to navigate through and slice open 3D representations of a patientâ€™s heart & Vision-based 3D tracking technologies and interactive features \\
 Singal et al. (2012) & Chemistry education & To provide an efficient way to represent and interact with molecules, leading to a better understanding of the spatial relation between molecules & AR technology for exhibiting the models \\
 Cerqueira and Kirner (2012) & Mathematics & To teach geometry through the use of 3D geometrical concepts & Head-mounted display and personal interaction panel  \\ 
 Mathison and Gabriel (2012) & Biology (School in the Park project) & To teach participants that habitats are connected like links in a chain (food chain) & AR experience  \\
 Coffin et al. (2008) &  Physics & To overlay graphics on top of the physical props to visualize these forces (speed, velocity, acceleration, pressure, friction, energy changes) invisible to the human eye  & Augmented video, video conferencing, tracked physical props (e.g. toy cars) \\
 Fleck Simon (2013) & Astronomy  & To show augmented views of the celestial bodies and support learning using spatial visual guides and views from a terrestrial observer & AR learning environment \\
 Martin et al. (2011) & History & To gather information and enhance the experience of visitors to cultural organisations (museums and games archaeological sites) & Mobile AR educational \\
 \hline
 \end{tabular}
  \caption{Meta-analysis of research on the use of AR in different fields of education. Cited from \cite{saidinar}  \label{tab:a} }
\end{table}


\section{Pitfalls and Limitations}
It is known that designing an application that actually improves the process of learning (no matter the form and the device it is running on) in a certain field is a task that requires serious research. 
As usual, these kinds of solutions are not that intuitive to use, for both teachers and students \cite{wu2013current}. 

From other technologies, AR's advantage is the fact that it offers a hands-on approach by integrating it's interactions capabilities directly \cite{akccayir2017advantages} with the reality (in forms of holograms). 
Closing the gap between real life teacher-driven learning and textbook-based classical learning. 
This advantage comes with a price, as latter forms of e-learning have been present and researched for years now, they have come to a more mature stage, some of them ready to enter in student's life.
As AR approaches it has the power to redefine everything, they have to catch up in making sure that these kinds of solutions are straightforward, thus simplifying the process of learning, not making it more complex \cite{carmigniani2011augmented}.

From a technological point of view, only with the progress of software and hardware from the past few years, AR has become feasible enough so that it can reach a broad audience of people \cite{puyuelo2013experiencing}. 
At the moment, mobile devices (Hand-Held AR) are the only ones that can bring AR to the masses \cite{wagner2007handheld}. 
The majority of high-end phones and tablets launched in the past year and a half, having AR capabilities \cite{liao2018mobile}. 
The other types of AR (like smart glasses) would offer a more immersive approach \cite{dunleavy2009affordances}, but the cost of such good these devices (like HoloLens \cite{kress201711} by Microsoft) makes them available only for companies and research purposes \cite{lee2012augmented}.

\chapter{Application in Musical Domain}

\section{Problem}
The importance of playing a musical instrument is indisputable, even as a side hobby, learning how to do such a thing provides real benefits to the life of an individual. Unfortunately, for people who do not possess the basic musical theoretical background, learning a musical instrument seems a hustle and is often abandoned from early stages. Even if this step is passed the number of people who are self-thought is small and benefiting from the services of a music school can be expensive or disruptive. Thus, finding new ways to increase the chances of developing for those who do not have access to a professor will provide a meaningful impact.

\section{Related Work}
\begin{figure}[H]
\includegraphics[width=0.7\textwidth]{flowkey}
\centering
\label{fig:hololens}
\caption{Concept of Flowkey application}
\end{figure}

Applications like FlowKey and Piano Maestro \cite{ng2015easy} dominate the section of self-learning piano playing. 
They work by continuously tracking the keys that are pressed (either by listening to the generated audio or by directly connecting the piano to an external computer). 
By using a screen that can be in the form of either a phone or a laptop, additional information can be rendered: 
\begin{itemize}
\item The progress you are making.
\item The accuracy. 
\item Tips on which fingers to use.
\end{itemize} 
But one of the most important facts is the ability to display the lyric sheet and hints that can be customized for beginners understanding or tailored for an advanced user. 
The other category of applications involves a more virtual approach. 
By eliminating the need of having a real piano or an organ; they allow versatility at the cost of losing the real tactile feedback and experience. 
These kinds of solutions are more suited for entertainment rather than having actual educational value.

\section{Solution}
\begin{figure}[H]
\includegraphics[width=0.7\textwidth]{piano}
\centering
\caption{HoloPiano Concept}
\label{fig:hpconcept}
\end{figure}

Our proposal, HoloPiano (See Fig. \ref{fig:hpconcept}) represents an application dedicated to people that are eager to learn the basics of piano playing. 
It uses Augmented Reality to show holograms over the keys, teaching the user how to play the selected lesson.


\begin{figure}[H]
\includegraphics[width=0.7\textwidth]{hololens}
\centering
\label{fig:hololens}
\caption{HoloLens device (from Microsoft)}
\end{figure}

As the name of the application is suggesting, we are using the first generation of HoloLens augmented glasses built by Microsoft.

In this case, Augmented Reality offers a unique approach to learning. 
Allowing users who do not have an extensive musical background to learn directly by practicing. 
By approaching and mastering different plays in order of their difficulty, grasping dexterity, and theoretical background simultaneously.

We headed towards an augmented approach (instead of a virtual reality one) due to the fact that it was a solution that would offer the actual tactile feedback that only a real piano key can provide. 
Moreover, as there is a multitude of piano and organ devices, all with different key sizes and specs (including low end, beginner purposed instruments), the capability to learn directly on the device you own, directly from the comfort of your own house represents a plus.

\section{Architecture}

\begin{figure}[H]
\includegraphics[width=0.9\textwidth]{HoloPianoStateDiagram}
\centering
\label{fig:feature-points}
\caption{HoloPiano application state diagram}
\end{figure}

The flow of the app is the following, after startup, for more easy computing the device is going the ask the user to pinpoint the corners of the piano (look at each corner and make a pinch gesture), when the piano is incapsulated correctly, along with this data HoloLens is going to take a camera snapshot and send everything to a server where the position of each key is going to be inferred, sent back and mapped by the HoloLens. From this point, the user can select a song base on its difficulty and start the process of playing (where holograms are going to be spawned upon the keys that are needed to be pressed).

An initial approach consisted in creating a Convolutional Neural Network that would infer the position of the piano and all its keys (without prompting to the user for specifying the pianos corners), but the first generation of HoloLens doesn't have support for running inference locally.

As a backup solution we had chosen to prompt for those corners and with image processing to just infer the position of all keys (as the application is designed to support multiple piano configurations), a process that is not as computing intensive as a convolutional neural network.

\subsection *{Detecting the piano keys}

\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.8\linewidth}
    \includegraphics[width=\linewidth]{piano-original}
     \caption{Original Image}
  \end{subfigure}
  \begin{subfigure}[b]{0.8\linewidth}
    \includegraphics[width=\linewidth]{piano-correction}
    \caption{Homographic correction and key contours}
  \end{subfigure}
  \begin{subfigure}[b]{0.8\linewidth}
    \includegraphics[width=\linewidth]{piano-points}
    \caption{Final result}
  \end{subfigure}
  \caption{Steps for detecting the piano keys (first case)}
  \label{fig:coffee3}
\end{figure}

\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.4\linewidth}
    \includegraphics[width=\linewidth]{piano-originalv2}
     \caption{Original Image}
  \end{subfigure}
  \begin{subfigure}[b]{0.577\linewidth}
    \includegraphics[width=\linewidth]{piano-correctionv2}
    \caption{Homographic correction and key contours}
  \end{subfigure}
  \begin{subfigure}[b]{0.7\linewidth}
    \includegraphics[width=\linewidth]{piano-pointsv2}
    \caption{Final result}
  \end{subfigure}
  \caption{Steps for detecting the piano keys (second case)}
  \label{fig:coffee3}
\end{figure}

After receiving the piano coordinates and the picture, using Homographic Correction \cite{opencvhomography}, the image is rotated such that all piano keys have a vertical angle, see Figure \ref{fig:coffee3}b. 
Then, using a watershed algorithm \cite{wang2009image} the contours of all the keys are generated and what is left is to filter the out-layers and to give each contour the musical note that it represents, see Figure \ref{fig:coffee3}c. 

The image processing script is written in Python \cite{oliphant2007python} (known for the accelerate speed of prototyping). 
Afterward, the script is wrapped into an API that receives POST request having in the body the image captured by the HoloLens along with the piano bounding box and returns a string that encodes the name and coordinates of each piano key.

\begin{figure}[H]
\includegraphics[width=0.95\textwidth]{holopiano-detection}
\centering
\label{fig:feature-points}
\caption{Interface of the detection script}
\end{figure}

\section{Limitations of The Device}

Unfortunately, after we have put together all the parts, we realized that the device is not powerful enough to maintain the holograms precisely on the position we are spawning them on. 
The holograms were drifting randomly over other piano keys, rendering the experience unusable.

The key component of our approach was the experience given by smart glasses, as other types of AR, like the one given by Handheld devices, still represents an unfeasible approach, as we do not want to place a phone or a tablet between the user and the piano.

We believe that in the near future, as the hardware and software are continuously improving, this approach is going to be realizable. 
At the moment of this writing, Microsoft announced a new version of HoloLens that is going to come with built-in AI capabilities and improve precision \cite{hololens2}.

\section{Alternative Approach}

\begin{figure}[H]
\includegraphics[width=1.0\textwidth]{piano-leds}
\centering
\label{fig:feature-points}
\caption{An alternative approach, a strip of LEDs glued to the piano}
\end{figure}

A more analog, but working path that we took is to replace HoloLens glasses with a strip of very small, individually controllable LEDs that are going to be stuck above the piano keys, one or two LEDs (depending on their size) are going to map one piano key directly. 

A few seconds before the user would need to press a piano key; the specific LEDs are going to be lit up, increasing in intensity until the moment they actually need to be pressed, then they will continue to blink prior to other keys needing to be pressed.

If by placing a camera above the piano, using image processing, we could detect if the required piano keys were actually pushed correctly and offer specialized lightning feedback and dynamic context advance of the song progress. Another option would be to use the already incorporated microphone to listen for the frequencies outputted by the piano.

For this approach, the strip of LEDs was connected to an Arduino board which exposes an API through that all the LEDs can individually be controlled. A Raspberry PI was used also used to orchestrate all the components.

One disadvantage of this approach is given by the variable number of keys a piano has and the variation in width that can occur (for each key in particular and for the gap between two keys), giving the need of calibration prior of permanently positioning the LEDs.

\section{Conclusion}
This generation of augmented reality enabled devices are not powerful enough to sustain such a use case, moreover at the current time these devices are in early stages, mainly targeting researchers and developers, their price making them unreasonable for the average individual. Fortunately, the progress towards newer iterations that will come with improved precision, performance, and better prices are soon to be released, rendering this approach valid.

From the point of view of bringing additional educational value, they truly have the potential to render the already available information on ways that could not be done before, thus being able to surpass even the classical in-class experience, even removing the limit of physically needing to be at a certain  time and location to benefit from such activity.

\chapter{Application in Computer Science}

\section{Problem}
As Computer Science is a field that is dramatically increasing in popularity and still not quite keeping yet with the demand, forming a way of thinking suitable for a programmer takes time and practice, but by starting at a younger age, when the mind is at it peaks in terms of forming and grasping new knowledge, the chances to be successful in this domain will drastically improve.


\section{Related Work}\label{related-arrobot}
These kinds of applications are already known for their efficiency, Hour of Code \cite{wilson2014hour} is one of the most popular platforms and movements (that hosts and encourages the apparition of code tutorials in this format). 
It became a global success with over 2 million students and a total of 750 millions hours of coding \cite{codeorg}. 
Its success is standing on gamifying the process of coding into a puzzle-solving activity that attracts people of all ages (from 5-year-old kids with animated levels to young adults). 
The goal of the project is to expose as many individuals as possible to one hour of code. 
An hour being a reasonable amount of time that is enough to spark an idea that can lead to a lifelong passion. 
The coding activities are usually found in a web or mobile format, making them easily accessible to the most used devices like laptops, mobile phones, and tablets.

\section{Solution}

\begin{figure}[H]
\includegraphics[width=1\textwidth]{arrobotdiagram}
\centering
\label{fig:arrobotdiagram}
\caption{ARRobotCode user case diagram}
\end{figure}

Using an iPad \cite{henderson2012ipad}, ARKit \cite{wang2018understanding}, and ScratchBlocks \cite{resnick2009scratch} we have developed a solution called \textit{ArRobotCode}.
The aim is to use Augmented Reality to aid in grasping the basic knowledge needed for writing algorithms. 
Everything is packed into a form that tries to be more tightly coupled with the reality, making abstract concepts accessible for beginners.

The lessons are presented in a level format (a multitude of stages organized by complexity and topic) in which the student role is to fly a spaceship from Earth to Moon. 
This can be done by providing a list of instructions so that the spaceship follows a given route and does not deviate.

We believe that by taking the already proved success of other similar initiatives (like the one presented in Section \ref{related-arrobot}) and adding all the benefits that come with Augmented Reality, will render a superior experience that will catch and be able to maintain the attention of a younger audience for longer periods of time.


\section{ScratchBlocks Instructions}
\begin{figure}[H]
\includegraphics[width=1.0\textwidth]{scratchblocks-2}
\centering
\label{fig:hololens}
\caption{Scratchblocks horizontal instructions}
\end{figure}

Scratch Blocks is a fork of Google's Blockly project \cite{fraser2014google} that provides a design specification and codebase for building creative computing interfaces dedicated to young children \cite{resnick2009scratch}. 
Together with the Scratch Virtual Machine (VM) \cite{scratchvm}, this codebase allows for the rapid design and development of visual programming interfaces. 
Unlike Blockly, Scratch Blocks does not use code generators, but rather leverages the Scratch Virtual Machine to create highly dynamic, interactive programming environments

\begin{figure}[H]
\includegraphics[width=1.0\textwidth]{scratchblocks}
\centering
\caption{Scratchblocks horizontal and vertical instructions comparation}
\label{fig:scratch-blocks}
\end{figure}

There are two types of blocks, horizontal and vertical (See Fig. \ref{fig:scratch-blocks}). 
The horizontal blocks provide a simpler UI, focused on visual indications instead of textual ones, the downside being that it is fairly limited. 
The vertical ones will be more familiar for those who have coded before, it allows for a more powerful set of instructions and more customization, this being the reason behind why it was chosen for this application, (See Fig. \ref{fig:customInstructions}).

\begin{figure}[H]
\includegraphics[width=0.4\textwidth]{allInstructions}
\centering
\caption{Instructions used in ArRobotCode}
\label{fig:customInstructions}
\end{figure}

\begin{figure}[H]
\includegraphics[width=0.4\textwidth]{newIf}
\centering
\label{fig:hololens}
\caption{Inline conditional instructions}
\end{figure}


For the purpose of this project, the instructions have been refined to be powerful enough but suited for the age group that is targeted.
We have kept only a subset of all the available instructions and categories, also we have updated them to contain more visual information (See Fig. \ref{fig:customInstructions}).


Inline conditional move instructions have been created to strip town the classical 'if'  to be more digestible for the youngest, basically it allows the spaceship to move or rotate towards a direction depending on the color of the tile that the spaceship is sitting on.
\section{Architecture}

\subsection*{Main Activity}
\begin{figure}[H]
\includegraphics[width=1.0\textwidth]{ArRobotCode0}
\centering
\caption{ArRobotCode main activity}
\label{fig:mainActivity}
\end{figure}

We designed the interface to focus mainly on user goals.
On the left side, multiple elements are displayed, starting from the upper left, an icon of the currently chosen character is shown, followed by a button to change the character.
On the same section, we provide a link to the menu that allows for a new level to be built and experimented with. 
The last element is a list of all the received and available achievements, see Figure \ref{fig:mainActivity}.

On the right side, the home screen consists of a list of the levels organized by difficulty. 
All the completed levels are marked accordingly with a green tick to stimulate the feeling of accomplishment. 
The icon of every entry is a small representation of the level, giving a hint about its difficulty. 

The levels are organized in chapters based on their difficulty and on different algorithmic aspects that they emphasize. 
The content can be dynamically changed directly from the application by users that have administrative privileges. 
The changes will propagate to all other users without the need to launch a separate update.

\subsection*{Game Activity}
\begin{figure}[H]
\includegraphics[width=1.0\textwidth]{ArRobotCode2}
\centering
\caption{ArRobotCode game activity}
\label{fig:gameScreen}
\end{figure}
The game screen is split into two parts, see Figure \ref{fig:gameScreen}. 
The left side is a WebView \cite{hazarika2014recommendations} that hosts a heavily modified version of ScratchBlock. 
And the right part consists of the Augmented Reality view that renders the game scene over reality. 
There is a bridge that allows permanent bi-directional communication between the two parties.

When the run button is pressed to execute the sequence of instructions an event is sent to the WebView signaling to trigger the compilation of the code. 
Forming a sequential list with all the instructions needed to be executed, if there is a forever instruction, the output will be of course truncated. 
When this list reaches the native section, the spaceship is moved to the initial position of the board.
Each sequence is executed one by one, one per second, to allow the user to observe every action and the exact moment an eventual mistake occurs. 
Before starting the movement animation of the spaceship, the native part sends an event to ScratchBlocks specifying witch instruction block is going to run, so that it glows, emphasizing it.

Horizontal plane detection is a builtin feature of ArKit and it is used right after a level was loaded. 
More exactly when the application is entering in a state where it searches for suitable places to render the scene. 
At that moment, by taping on one of the places, the user can select the plane where the actual game scene is going to be instantiated. 
Due to the fact that the plane dimensions are variable (it can be spawned on a large floor or on a tight table), the scene scales accordingly. 
This process happens every time a new level is loaded, to enable a new location to be used.

\subsection*{Level Builder}

\begin{figure}[H]
\includegraphics[width=1.0\textwidth]{ArRobotCode3}
\centering
\caption{ArRobotCode level builder interface}
\label{fig:buildinglvl}
\end{figure}

One of the most important features is the in-game level builder that allows users to create and experiment with their own levels, providing a significant boost in creativity and understanding, see Figure: \ref{fig:buildinglvl}. 

The view is split in tiles of the following types:

\begin{itemize}
\item Start position - Spaceship
\item End position - Moon
\item Free - the gray tiles
\item Four types of occupied tiles (hence enabling functional diversity in level creation): Pink, Orange, Blue, Green and Purple
\end{itemize}

In order to interact with User Interface in the building menu, the user has to use a few predefined gestures:
\begin{itemize}
\item A simple tap to switch between a free tile and a default green occupied one.
By swiping right or left on an occupied tile, one can cycle between the five different available colors. 
\item In order to trigger the starting position, a long tap is required.
\item If tapping one more time the end tile will appear.
\item Three taps will reset back to being a free cell.
\end{itemize}

The grid size is also customizable, the number of rows and columns can be changed from the inputs that are situated on top of the screen. 

If the account has administrative privileges, like in figure \ref{fig:buildinglvl} two extra inputs are available: 
\begin{itemize}
\item A text field that contains the name of the category that the level is going to have. 
\item A toggle to publish the new changes.
\end{itemize} 

There is also the possibility to test the levels while building them by using the dedicated button.

\subsection*{Data Persistence}

\begin{figure}[H]
\includegraphics[width=0.92\textwidth]{ArRobotCodePersistUML}
\centering
\label{fig:arrobotcode-persist}
\caption{Data Persistence UML for ARRobotCode}
\end{figure}


Cloud Firestore (from FireBase) \cite{wingerath2019real} is used as the persistence layer, it is a scalable NoSQL \cite{strauch2011nosql} cloud-hosted database with offline mode and syncing capabilities.

It supports flexible, hierarchical data structure, files being organized in documents (the equivalent of tables from SQL) that further split into collections. It features real-time support, callbacks that are triggered if a substructure of the registered node is updated. Even if the application is in an offline state, all the data changes are going to be cached and then synced when the device comes back online. It also enables authentication integration with 3rd party services, in ArCode the option for one-click Google login is used, no other data is requested from the user.

For the purpose of this project the data is divided into four collections:
\begin{enumerate}
\item Users: besides basic user information like the token, role, it contains the currently selected character and a reference to all the completed achievements and levels
\item Levels: name, chapter name, height, width, reference to the user that created it, boolean specifying if the level is public or not and a sub-list of width*height length containing the type of tile
\item Characters: name of the character, icon and the number of completed levels required for unlocking it
\item Achievements: name of the achievement, a short description, and its picture
\end{enumerate}

\subsection*{Reactive Programming}

\begin{figure}[H]
\includegraphics[width=0.6\textwidth]{streams}
\centering
\label{fig:reactive-pgrogramming}
\caption{Example of reactive programming }
\end{figure}

Represents programming with asynchronous data streams. Its functional part is what makes it a truly elegant way of writing code \cite{reactivex}. Streams are cheap, ubiquitous and basically, anything can be a stream: variables, user input, properties, data structures, etc. A stream can be used as an input to other streams, it can be merged into two streams, filtered to get only the events that impose interest, mapped to other values and so on.

\begin{figure}[H]
\includegraphics[width=1.0\textwidth]{observable-doc}
\centering
\label{fig:feature-points}
\caption{ Observables scheme \cite{reactivex} }
\end{figure}

An observer subscribes to an Observable \cite{meijer2010reactive} making it react to whatever item or sequence of items the Observable emits. Concurrent operations are facilitated by using this pattern as there is no need to block while waiting for an Observable to emit object.

A subject is a bridge or a proxy that acts both as an observer and as an Observable. Because it is an observer, it can subscribe to one or more observables and because it is an observable it can pass through the items it has observed by reemitting them, it can also emit new items.

There are four varieties of a Subject, all designed for different use cases:
\begin{enumerate}
\item Async Subject: emits only the last value emitted by the source Observable and only after that source Observable completes
\item Behaviour Subject: when an observer subscribes to a BehaviourSubject, it begins by emitting the item most recently emitted by the source Observable
\item Public Subject: it emits to an observer only the items that have been emitted by the source Observable subsequent to the time of subscription
\item Replay Subject: it emits to any observer all the items that were emitted by the source Observable, regardless of when the observer subscribes. Some implementations replay only a specific number of past emitted events.
\end{enumerate}

RxSwift \cite{pillet2017rxswift} is the implementation of Rx that was used extensively throughout this project. Alongside it, RxGesture was used to provide Rx capabilities for detecting different gestures like pan, rotation, swipe and so on.

The application contains multiple repositories for levels, users, characters, and achievements. Each repository is treated as a single source of truth and data propagation throughout all the views, for this reason, each repository is also a singleton. The repositories output an observable allowing different parts of the program to subscribe and watch for any changes. The outputted observable observes an internal Replay Subject having a buffer size of 1, this allows for every component and the subscription time to receive the latest version of the data without needing to wait until new data is emitted.

\begin{figure}[H]
\includegraphics[width=1.0\textwidth]{reactive-repository}
\centering
\label{fig:reactive-repository}
\caption{Repository integration with reactive programming }
\end{figure}

The instructions captured from ScratchBlocks JavaScript virtual machine are enqueued in a Behaviour Subject for the AR rendering controller that takes one instruction per second and executes it. The role of the delay is to provide enough time for the animations to finish rendering. 

One advantage of using reactive programming comes from easily being able to change the thread used for the subscription and observer code (thus leaving the main thread as uncluttered as possible to keep the smoothness of the user interface)
\begin{figure}[H]
\includegraphics[width=0.8\textwidth]{reactive-instructions}
\centering
\label{fig:reactive-repository}
\caption{Processing instructions stream using reactive programming}
\end{figure}

Model-view-viewmodel pattern \cite{anderson2012model}, along with reactive programming, was used to facilitate the interaction with the graphical user interface.

\begin{figure}[H]
\includegraphics[width=1.0\textwidth]{mvvm}
\centering
\label{fig:reactive-repository}
\caption{MVVM patern architecture }
\end{figure}

\begin{enumerate}
\item Model is the domain object, it represents the actual data 
\item View is the presentation of the data, what the final users see. It allows for interaction to take place, such as accepting new input or modifying already existing data
\item ViewModel is a key piece of the triad on the ground that it introduces Presentation Separation.  Instead of making the model aware of the userâ€™s view of the data, the model simply holds the data, the view just holds the formatted data, and the controller is the one that acts as the liaison between the two. The controller might take input from the view and place it on the model, or it might interact with a service to retrieve the model, then translate properties and place it on the view.
\end{enumerate}

The Data Binding part is where the reactive programming really shines by helping to reduce the event/callback clutter. Also, the ViewModel is outputting an observable so that the user interface can subscribe and automatically updates the changes that occur in the Model.


\begin{figure}[H]
\includegraphics[width=1.0\textwidth]{reactive-ui}
\centering
\label{fig:reactive-repository}
\caption{Data binding using reactive programming}
\end{figure}

\subsection*{Augmented Reality Module Architecture}

\begin{figure}[H]
\includegraphics[width=0.9\textwidth]{ArRobotCodeUML}
\centering
\label{fig:feature-points}
\caption{ Augmented Reality module class diagram }
\end{figure}

As ArKit only provides basic methods for functionality like plane finding or object spawning, a higher level system had to be built in order to interact with all these components in a reliable, maintainable and extensible way, in other words, a game engine.

Following the path of executing a \textit{move front if} instruction, the first step is for the instruction observer to encounter and start processing  it:
\begin{figure}[H]
\includegraphics[width=0.9\textwidth]{move-front-if-1}
\centering
\label{fig:feature-points}
\caption{ First step in moveFrontIf execution }
\end{figure}

Moving on to the EngineAr \textit{moveFrontIf} instruction, at first the state of the game is checked, if it has ended the execution will be canceled, otherwise if the current tile's color matches the color specified in the conditional instruction, the instruction changes into a simple, unconditional \textit{moveFront()}.

The \textit{DispatchQueue.main.async} is needed on the grounds that the entire \textit{moveFrontIf} instruction is executed on a background thread (decision made for keeping the main thread dedicated to UI operations) and changing the text of the status is a UI related operation that can be executed only on the main thread.

\begin{figure}[H]
\includegraphics[width=1.0\textwidth]{move-front-if-2}
\centering
\label{fig:feature-points}
\caption{ Second step in moveFrontIf execution }
\end{figure}

\textit{MoveFront} checks again for the game not to be completed, and if this happens the player's position is virtually moved to the new position and the PlayerAr's method of moveFront is called. 

This extra layer of abstraction is needed in case the Augmented Reality render system is switched to another type of visualization, as the state of the game is already kept in memory, only the last layer of visualization needing to be updated.
\begin{figure}[H]
\includegraphics[width=0.6\textwidth]{move-front-if-3}
\centering
\label{fig:feature-points}
\caption{ Third step in moveFrontIf execution }
\end{figure}

This method is the final one from the chain, being the most low-level as it physically translates the position of the spaceship within a period of time (one second in this case).
\begin{figure}[H]
\includegraphics[width=1.0\textwidth]{move-front-if-4}
\centering
\label{fig:feature-points}
\caption{ Final step in moveFrontIf execution}
\end{figure}


\section{Gamification}
\begin{figure}[H]
\includegraphics[width=0.65\textwidth]{gamification}
\centering
\label{fig:feature-points}
\caption{ Matrix classifing concepts related to gamification \cite{deterding2011gamification} }
\end{figure}

As the target public is formed of young students of age 5 to 15, packing the application in a form that would appeal to them represents a vital aspect.
Also we need to envelop the learning process into an interactive game for maximizing the retention and the impact of such an application. 

Although proper evaluation is mostly missing, the majority of the authors of the reviewed papers share the opinion that gamification has the potential to improve learning \cite{dicheva2015gamification}. 
Therefore, more substantial empirical research is needed to investigate, in particular, the motivating effects of using single game elements in specific educational contexts and for particular types of learners. 

At the first look, the aspect of an application is enough to catch the attention of a kindergarten student, but especially at these ages, the children have the tendency to be drawn toward new activities rather than sticking to already known ones.
From an educational point of view in order to actually make a difference, the rate of retention is crucial, keeping them focused, motivated and willing to return in the application for the purpose of completing other levels.

Gamification helps this purpose by offering a collection of techniques:

\begin{itemize}
\item Games adapt their difficulty to be slightly harder than the player skill.
\item The ability to receive items when a certain point has been reached, in other words, this represents a do-reward mechanism.
\item Settings a series of goals (through achievements for the case of this application).
\item Integration with the real world, Augmented Reality being a powerful technique.
\item The ability to self-express, to either customize certain elements (like the chosen character) or create (through the level builder).
\end{itemize}

\subsection*{Hero choser}
\begin{figure}[H]
\includegraphics[width=0.89\textwidth]{ArRobotCode1}
\centering
\label{fig:feature-points}
\caption{ArRobotCode hero chooser interface}
\end{figure}

Unlocking new characters that relate to the personality of the student is a motivator to continue playing and solving levels so that the risk of abandonment is diminished, and the feeling of accomplishment is stimulated.

Each character has a number of levels that must be successfully completed in order to unlock them.  
By default, there are two characters unlocked such that they discover the functionality and realize that more is to be unlocked if they complete enough levels.

The benefits of unraveling a new character are only aesthetic, no actual advantage is being given in the game, but this has not proved to negatively affect the user experience on the grounds of their age.

%The aspect of the characters is chosen to reflect the general theme of the game, space exploration, a topic known to attract people of all ages, especially kids.

From a technical point of view, the list of characters is shown into a modal window rendering over the Main Activity. 
Collection View was used as a container rendering two elements per row, and in order to allow the selection of different available characters, a tap listener is in place for every element shown in the collection view.

\subsection*{Achievements}
 
 \begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.3\linewidth}
    \includegraphics[width=\linewidth]{ArRobotCodeAchiv1}
     \caption{For completing a level}
     
  \end{subfigure}
  \begin{subfigure}[b]{0.3\linewidth}
    \includegraphics[width=\linewidth]{ArRobotCodeAchiv2}
    \caption{For completing 10 levels}
  \end{subfigure}
  \begin{subfigure}[b]{0.3\linewidth}
    \includegraphics[width=\linewidth]{ArRobotCodeAchiv3}
    \caption{For completing a section }
  \end{subfigure}
  \begin{subfigure}[b]{0.3\linewidth}
    \includegraphics[width=\linewidth]{ArRobotCodeAchiv4}
    \caption{For building a level}
  \end{subfigure}
  \caption{ ArRobotCode list of Achievements}
  \label{fig:coffee3}
\end{figure}

On the ground that the number of completed levels is not the only quantification of the user's progress. 
Achievements stimulate the usage of certain features of the application in some specific ways that ultimately bring benefits to the experience of learning.

More specifically, achievements can direct the user to only use certain instructions for some levels (or chapters of levels) so that they are encouraged to find different ways to solve similar problems. 
Other aspects that can be targeted are the speed of coding, the precision with which they solve challenges, number of tries until their code is correct.

\section{Conclusion}
This type of augmented reality has got to a level that is mature enough to reach the general public. From a development point of view, ArKit is stable and intuitive to use, rendering impressive results. The only drawback being the fact that the mobile devices that are ArKit (or ArCore in Android's case) enabled need to be pretty high-end, but the bar will go down in the next few years. 

The application that we presented is only a use-case, an example of what is really possible to achieve with augmented reality. Beside the option to \textit{augment} existing solutions giving them a boost in quality, retention, and effectiveness, there is a second option of completely redefining what is possible, an option that is still open for active research.

ArRobotCode has received positive feedback from kids within the target age range, being able to see the spaceship moving through the real world, even more, giving them the power to move it as they wish seems to be high motivator factor in their desire to experiment with the first steps of computer programming.


\chapter{Conclusion}
In this paper, we showed how integrating Augmented Reality into a product can increase its value. 
Education was the targeted domain, more specifically the musical and computer science fields through two separate applications.

\textit{HoloPiano} is a solution that uses a pair of augmented glasses (HoloLens for this domain) in order to teach students of all ages the basics of playing the piano by rendering holograms above the keys that need to be pressed. 
The utility of Augmented Reality comes from enabling a new type of user interface that is more intuitive, especially for complete beginners, thus providing a boost in the learning experience. 
The conclusion from this approach was that at the current time of this writing, on the ground of the limitations of this generation of available hardware, such an approach is still not viable. 
%also from the point of view of distributing the final product to the masses, the steepness of the price results in a low power of distributing the product.

\textit{ArRobotCode} targets a young audience for the purpose of guiding their first steps into the field of programming. 
The effectiveness of successfully teaching one the basic concepts that stand behind coding can only come from prolonged exposure time.
For this to happen, especially at the ages of 5 to 12 years old, gamification must be rooted into the core mechanisms of the application. 
Augmented Reality provides a real benefit in this due to the fact that it brings abstract knowledge closure to the reality and it improves the feeling of accomplishment.
% (by giving them the power to make an object, a spaceship, in this case, move through the reality) and it simply provides a more interesting way of interacting with the user (aspect that is really important for keeping a child-focused). 
This category of mobile Augmented Reality has reached a mature enough phase and currently is ready for mass distribution. 
%At the moment, the kind of devices it runs on is part of the high-end sector but the bar is in continuous decrease.

While the boost from the first application was given by the visualization capabilities introduced by Augmented Reality, in the second presented work, gamification is the aspect that made an impact. 
Hence, Augmented Reality provides a multitude of use-cases that can be exploited, having the power to redefine even well-established techniques. 
Moreover, the fast pace of advancing continuously enlarges these possibilities.

The educational sector has been improving its techniques for thousands of years, from providing a way to persist information throughout time by writing it on different materials, until formalizing it into a well defined educational system. 
At the moment, the technological progress made it all more straightforward to access, at any time, from any place, and Augmented Reality has the power to take it a step forward.

This work and the domain it envisions can be improved by reiterating different solutions and so exploiting the accelerate progress of hardware and software while also keeping a close feedback loop between the creators of these systems and their users.
In the future we intend to apply the technique to other fields like healthcare, to help the student learn how to perform routine tasks like performing an intravenous injection of magnesium sulphate or how to perform cardiopulmonary resuscitation (CPR). 
Or in aeronautics, to teach the student how to land a glider, perform a ballistic descent or other critical tasks that would otherwise need access to expensive equipment or can be learned only in certain locations.


\bibliography{references}
\bibliographystyle{unsrt} 

\end{document}